#!/usr/bin/env python3
"""
ä¿®å¤ Markdown æ–‡ä»¶çš„"å…¨å‘˜æ ‡é¢˜ç—…"é—®é¢˜

é—®é¢˜ï¼šé£ä¹¦æ–‡æ¡£è½¬æ¢åï¼Œæ¯æ®µæ–‡å­—éƒ½è¢«åŠ ä¸Šäº† # (ä¸€çº§æ ‡é¢˜)
ç—‡çŠ¶ï¼šæ–‡ä»¶ä¸­è¶…è¿‡ 50% çš„éç©ºè¡Œä»¥ # å¼€å¤´

è§£å†³æ–¹æ¡ˆï¼šå°† # ä¸€çº§æ ‡é¢˜ é™çº§ä¸º æ™®é€šæ–‡æœ¬
"""

import os
import re

# é…ç½®
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
KNOWLEDGE_BASE_DIR = os.path.join(BASE_DIR, "knowledge_base")
THRESHOLD = 0.5  # è¶…è¿‡ 50% åˆ™åˆ¤å®šä¸ºå¼‚å¸¸


def is_header_line(line):
    """åˆ¤æ–­æ˜¯å¦æ˜¯ä¸€çº§æ ‡é¢˜è¡Œ"""
    stripped = line.lstrip()
    return stripped.startswith("# ") and not stripped.startswith("##")


def analyze_file(filepath):
    """åˆ†ææ–‡ä»¶ï¼Œè¿”å›ç»Ÿè®¡ä¿¡æ¯"""
    with open(filepath, "r", encoding="utf-8") as f:
        content = f.read()
        lines = content.splitlines()

    non_empty_lines = [l for l in lines if l.strip()]
    header_lines = [l for l in non_empty_lines if is_header_line(l)]

    total_non_empty = len(non_empty_lines)
    header_count = len(header_lines)
    ratio = header_count / total_non_empty if total_non_empty > 0 else 0

    # æ£€æµ‹æ˜¯å¦æœ‰å¤šä½™ç©ºè¡Œï¼ˆè¿ç»­è¶…è¿‡2ä¸ªç©ºè¡Œï¼‰
    extra_empty_lines = 0
    consecutive_empty = 0
    for line in lines:
        if line.strip() == "":
            consecutive_empty += 1
            if consecutive_empty > 2:
                extra_empty_lines += 1
        else:
            consecutive_empty = 0

    # æ£€æµ‹æœ‰åºåˆ—è¡¨ç¼–å·é—®é¢˜ï¼ˆè¿ç»­çš„ 1. 1. 1.ï¼‰
    bad_list_count = 0
    prev_was_list = False
    for line in lines:
        stripped = line.strip()
        is_list = re.match(r'^1\.\s', stripped) is not None
        if is_list and prev_was_list:
            bad_list_count += 1
        prev_was_list = is_list

    # æ£€æµ‹ç©ºçš„ ### æ ‡é¢˜
    empty_headers = 0
    for line in lines:
        stripped = line.strip()
        if re.match(r'^###\s*$', stripped):
            empty_headers += 1

    # æ£€æµ‹è¡Œå°¾ç©ºæ ¼
    trailing_spaces = sum(1 for line in lines if line != line.rstrip())

    needs_clean = ratio > THRESHOLD and header_count > 5
    needs_clean = needs_clean or extra_empty_lines > 0
    needs_clean = needs_clean or bad_list_count > 0
    needs_clean = needs_clean or empty_headers > 0
    needs_clean = needs_clean or trailing_spaces > 0

    return {
        "total_lines": len(lines),
        "non_empty_lines": total_non_empty,
        "header_lines": header_count,
        "ratio": ratio,
        "is_abnormal": needs_clean,
        "extra_empty_lines": extra_empty_lines,
        "bad_list_count": bad_list_count,
        "empty_headers": empty_headers,
        "trailing_spaces": trailing_spaces,
    }


def clean_file(filepath):
    """ä¿®å¤æ–‡ä»¶ï¼šå°† # ä¸€çº§æ ‡é¢˜ é™çº§ä¸ºæ™®é€šæ–‡æœ¬ï¼Œå¹¶æ¸…ç†å¤šä½™ç©ºè¡Œï¼Œä¿®å¤æœ‰åºåˆ—è¡¨ç¼–å·ï¼Œç§»é™¤ç©ºæ ‡é¢˜å’Œè¡Œå°¾ç©ºæ ¼"""
    with open(filepath, "r", encoding="utf-8") as f:
        content = f.read()

    original_lines = len(content.splitlines())
    original_header_count = len(re.findall(r'^#[ \t]', content, re.MULTILINE))

    # å°† # å¼€å¤´çš„è¡Œï¼ˆä½†ä¸æ˜¯ ## æˆ–æ›´æ·±çš„ï¼‰æ›¿æ¢ä¸ºç©º
    cleaned_lines = []
    for line in content.splitlines():
        stripped = line.lstrip()
        if stripped.startswith("# ") and not stripped.startswith("##"):
            # å»æ‰è¡Œé¦–çš„ #ï¼Œä¿ç•™ç¼©è¿›
            match = re.match(r'^([ \t]*)(.*)', line)
            if match:
                prefix = match.group(1)
                rest = match.group(2).lstrip()
                if rest.startswith("# "):
                    cleaned_lines.append(prefix + rest[2:])  # å»æ‰ # å’Œåé¢çš„ç©ºæ ¼
                else:
                    cleaned_lines.append(line)
            else:
                cleaned_lines.append(line)
        else:
            cleaned_lines.append(line)

    # ä¿®å¤æœ‰åºåˆ—è¡¨ç¼–å·ï¼šå°† "1. 1. 1. " æ›¿æ¢ä¸ºé€’å¢çš„ "1. 2. 3. "
    fixed_lines = []
    list_counter = 0
    prev_was_list = False

    for line in cleaned_lines:
        stripped = line.strip()

        # æ£€æµ‹æ˜¯å¦ä¸ºæœ‰åºåˆ—è¡¨é¡¹ï¼ˆä»¥ "1. " å¼€å¤´ï¼Œä¸”ä¸Šä¸€è¡Œä¹Ÿæ˜¯åˆ—è¡¨æˆ–å½“å‰è¡Œä¹‹å‰æœ‰åˆ—è¡¨ï¼‰
        is_list = re.match(r'^1\.\s', stripped) is not None

        if is_list:
            if not prev_was_list:
                list_counter = 1  # æ–°åˆ—è¡¨å¼€å§‹
            else:
                list_counter += 1  # åˆ—è¡¨ç»§ç»­ï¼Œé€’å¢
            # æ›¿æ¢ "1. " ä¸ºæ­£ç¡®çš„åºå·
            fixed_line = re.sub(r'^1\.', f'{list_counter}.', line)
            fixed_lines.append(fixed_line)
            prev_was_list = True
        else:
            fixed_lines.append(line)
            prev_was_list = False

    # æ¸…ç†ç©ºçš„ ### æ ‡é¢˜å’Œå¤šä½™çš„ç©ºè¡Œ
    final_lines = []
    empty_count = 0
    extra_empty_removed = 0
    empty_headers_removed = 0

    for line in fixed_lines:
        stripped = line.strip()

        # ç§»é™¤ç©ºçš„ ### æ ‡é¢˜
        if re.match(r'^###\s*$', stripped):
            empty_headers_removed += 1
            continue

        if stripped == "":
            empty_count += 1
            if empty_count <= 2:  # æœ€å¤šä¿ç•™2ä¸ªç©ºè¡Œ
                final_lines.append(line)
            else:
                extra_empty_removed += 1  # ç§»é™¤å¤šä½™çš„ç©ºè¡Œ
        else:
            empty_count = 0
            # ç§»é™¤è¡Œå°¾ç©ºæ ¼
            final_lines.append(line.rstrip())

    cleaned = "\n".join(final_lines)
    new_lines = len(cleaned.splitlines())

    # ç»Ÿè®¡ä¿®å¤çš„æœ‰åºåˆ—è¡¨æ•°é‡
    original_list_count = len(re.findall(r'\n1\.', '\n' + content))
    current_list_count = len(re.findall(r'\n1\.', '\n' + cleaned))
    lists_fixed = original_list_count - current_list_count

    # å†™å›æ–‡ä»¶
    with open(filepath, "w", encoding="utf-8") as f:
        f.write(cleaned)

    return {
        "original_lines": original_lines,
        "new_lines": new_lines,
        "headers_removed": original_header_count,
        "extra_empty_removed": extra_empty_removed,
        "lists_fixed": lists_fixed,
        "empty_headers_removed": empty_headers_removed,
    }


def main():
    print("=" * 60)
    print("Markdown æ–‡ä»¶æ ¼å¼ä¿®å¤å·¥å…·")
    print("=" * 60)
    print(f"æ‰«æç›®å½•: {KNOWLEDGE_BASE_DIR}")
    print(f"åˆ¤å®šé˜ˆå€¼: è¶…è¿‡ {THRESHOLD * 100:.0f}% çš„éç©ºè¡Œæ˜¯ # æ ‡é¢˜")
    print("=" * 60)

    if not os.path.exists(KNOWLEDGE_BASE_DIR):
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {KNOWLEDGE_BASE_DIR}")
        return

    md_files = [f for f in os.listdir(KNOWLEDGE_BASE_DIR) if f.endswith(".md")]
    print(f"æ‰¾åˆ° {len(md_files)} ä¸ª .md æ–‡ä»¶\n")

    fixed_files = []
    abnormal_files = []

    # ç¬¬ä¸€éï¼šåˆ†æ
    for filename in md_files:
        filepath = os.path.join(KNOWLEDGE_BASE_DIR, filename)
        stats = analyze_file(filepath)

        if stats["is_abnormal"]:
            abnormal_files.append((filename, stats))
        else:
            issues = []
            if stats.get("extra_empty_lines", 0) > 0:
                issues.append(f"{stats['extra_empty_lines']} å¤„å¤šä½™ç©ºè¡Œ")
            if stats.get("empty_headers", 0) > 0:
                issues.append(f"{stats['empty_headers']} ä¸ªç©ºæ ‡é¢˜")
            if stats.get("trailing_spaces", 0) > 0:
                issues.append(f"{stats['trailing_spaces']} å¤„è¡Œå°¾ç©ºæ ¼")
            if issues:
                print(f"  âœ… {filename} (æ­£å¸¸, {', '.join(issues)} å·²æ¸…ç†)")
            else:
                print(f"  âœ… {filename} (æ­£å¸¸, æ ‡é¢˜å æ¯” {stats['ratio']*100:.1f}%)")

    print("-" * 60)

    # ç¬¬äºŒéï¼šä¿®å¤å¼‚å¸¸æ–‡ä»¶
    for filename, stats in abnormal_files:
        filepath = os.path.join(KNOWLEDGE_BASE_DIR, filename)
        result = clean_file(filepath)

        fixed_files.append({
            "filename": filename,
            "original_lines": result["original_lines"],
            "new_lines": result["new_lines"],
            "headers_removed": result["headers_removed"],
            "extra_empty_removed": result.get("extra_empty_removed", 0),
            "empty_headers_removed": result.get("empty_headers_removed", 0),
            "lists_fixed": result.get("lists_fixed", 0),
        })

        print(f"  ğŸ”§ å·²ä¿®å¤: {filename}")
        print(f"     æ ‡é¢˜å æ¯”: {stats['ratio']*100:.1f}%")
        print(f"     è¡Œæ•°: {result['original_lines']} â†’ {result['new_lines']}")
        print()

    # æ€»ç»“
    print("=" * 60)
    print("ä¿®å¤å®Œæˆï¼")
    print("=" * 60)
    print(f"æ‰«ææ–‡ä»¶æ•°: {len(md_files)}")
    print(f"æ­£å¸¸æ–‡ä»¶æ•°: {len(md_files) - len(abnormal_files)}")
    print(f"ä¿®å¤æ–‡ä»¶æ•°: {len(fixed_files)}")

    total_headers = sum(f["headers_removed"] for f in fixed_files)
    total_empty_lines = sum(f.get("extra_empty_removed", 0) for f in fixed_files)
    total_lists_fixed = sum(f.get("lists_fixed", 0) for f in fixed_files)
    total_empty_headers = sum(f.get("empty_headers_removed", 0) for f in fixed_files)

    if fixed_files:
        print(f"\nå…±ç§»é™¤: {total_headers} ä¸ª # æ ‡é¢˜, {total_empty_lines} å¤„å¤šä½™ç©ºè¡Œ, {total_empty_headers} ä¸ªç©ºæ ‡é¢˜, ä¿®å¤ {total_lists_fixed} ä¸ªåˆ—è¡¨ç¼–å·")
        print("\nä¿®å¤åçš„æ–‡ä»¶åˆ—è¡¨:")
        for f in fixed_files:
            info = []
            if f["headers_removed"] > 0:
                info.append(f"ç§»é™¤ {f['headers_removed']} ä¸ªæ ‡é¢˜")
            if f.get("extra_empty_removed", 0) > 0:
                info.append(f"æ¸…ç† {f['extra_empty_removed']} å¤„ç©ºè¡Œ")
            if f.get("empty_headers_removed", 0) > 0:
                info.append(f"ç§»é™¤ {f['empty_headers_removed']} ä¸ªç©ºæ ‡é¢˜")
            if f.get("lists_fixed", 0) > 0:
                info.append(f"ä¿®å¤ {f['lists_fixed']} ä¸ªåˆ—è¡¨")
            info_str = f" ({', '.join(info)})" if info else ""
            print(f"  - {f['filename']}{info_str}")


if __name__ == "__main__":
    main()
